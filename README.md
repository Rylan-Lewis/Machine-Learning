# Machine Learning: A Repo of core Machine Learning concepts applied which involves heavy data pre-processing, data analysis, feature engineering, classical ML algorithms and inferences.

1: Vertebral Column Classification with KNN: This project performs binary classification (Normal vs Abnormal) on the UCI Vertebral Column dataset using K-Nearest Neighbors, including preprocessing, exploratory data analysis, and careful train–test splitting. It evaluates KNN performance across different values of k, training set sizes (learning curves), distance metrics (Euclidean, Manhattan, Minkowski, Chebyshev, Mahalanobis), and weighted voting, reporting error rates and classification metrics.

2: Combined Cycle Power Plant Regression Analysis: This project explores and models power plant energy output using environmental variables through extensive EDA, simple and multiple linear regression, interaction and nonlinear modeling, and model selection via statistical significance and MSE. It further compares optimized linear regression models with KNN regression (using raw and normalized features) to evaluate predictive performance and generalization.

3: Time Series Classification – Part 1 (Feature Extraction): This part focuses on preprocessing the AReM multisensor time-series dataset and extracting informative time-domain features (e.g., min, max, mean, quartiles, standard deviation) from multiple sensor streams, along with statistical analysis and bootstrap confidence intervals to identify the most important features.

4: Time Series Classification – Part 2 (Binary & Multiclass Modeling): This part applies the extracted features to build and evaluate classification models, including logistic regression (with feature selection, interactions, and L1 regularization), Naïve Bayes, and multinomial classifiers, using cross-validation, ROC/AUC analysis, and confusion matrices to compare binary and multiclass activity recognition performance.

5: Interpretable Models & Regularized Regression: This assignment builds interpretable decision tree models on medical data, including rule extraction and cost-complexity pruning, to emphasize transparency and simplicity. It then applies and compares regularized and ensemble regression techniques (OLS, Ridge, LASSO, PCR, and L1-penalized boosting/XGBoost) on the Communities and Crime dataset, evaluating feature importance and test performance via cross-validation.

6: Tree-Based Models for Imbalanced Data with Class Imbalance Handling with SMOTE: This assignment analyzes the highly imbalanced APS Failure dataset using tree-based methods, including random forests and XGBoost model trees with L1-penalized logistic regression, along with missing-value imputation, feature analysis, and extensive performance evaluation (ROC, AUC, confusion matrices). It further investigates strategies for addressing severe class imbalance by incorporating class-weighted models and SMOTE-based resampling, comparing uncompensated and balanced approaches through cross-validation and test-set performance.

7: Multi-Label Classification with SVMs + Unsupervised Learning with K-Means: This assignment tackles multi-class, multi-label classification on the Anuran Calls dataset using SVMs with Gaussian and L1-penalized kernels, evaluated via exact match and Hamming metrics, and enhanced through cross-validation, feature standardization, and class imbalance handling (SMOTE). It also explores k-means clustering for multi-label data using Monte Carlo simulations, automatic selection of the optimal number of clusters, and evaluation through Hamming distance, score, and loss by comparing cluster-assigned labels with ground truth.

8: Supervised, Semi-Supervised & Unsupervised Learning Comparison + Active vs Passive Learning with SVMs: This assignment compares L1-penalized SVMs, self-training (semi-supervised learning), k-means, and spectral clustering on the Breast Cancer Wisconsin dataset using Monte Carlo simulations, evaluating performance via accuracy, precision, recall, F1-score, and AUC. It further investigates active learning by incrementally training SVMs on the Banknote Authentication dataset, contrasting uncertainty-based sample selection with random sampling and analyzing learning curves through repeated Monte Carlo simulations.

9: Transfer Learning for Jute Pest Image Classification: This project develops and evaluates a multi-class image classifier for 17 jute pest species using transfer learning with pre-trained CNNs (ResNet, EfficientNet, VGG, DenseNet), incorporating data augmentation, regularization, early stopping, and comprehensive comparison across precision, recall, F1-score, and AUC to identify the best-performing model.
