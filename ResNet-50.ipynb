{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rylan-Lewis/Machine-Learning/blob/main/ResNet-50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkLc6sNZRywb",
        "outputId": "303373c2-ecf0-4982-a656-a1f9922aa810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cB4wuvZH47E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BbW7JU2H8ch"
      },
      "outputs": [],
      "source": [
        "#We are now making the blocks(set of 3 layers) which will be used throughout the model\n",
        "class block(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,identity_downsample=None , stride=1):\n",
        "        super(block,self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=1, stride=1,padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride,padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3=nn.Conv2d(out_channels,out_channels*self.expansion,kernel_size=1,stride=1,padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        identity=x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity=self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtaLXXGvH_Fb"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self,block,layers,image_channels,num_classes):\n",
        "        super(ResNet,self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels,64,kernel_size=7,stride=2,padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
        "\n",
        "        #resNet layers\n",
        "        self.layer1 = self.make_layer(block,layers[0],out_channels=64,stride=1)\n",
        "        self.layer2 = self.make_layer(block,layers[1],out_channels=128,stride=1)\n",
        "        self.layer3 = self.make_layer(block,layers[2],out_channels=256,stride=1)\n",
        "        self.layer4 = self.make_layer(block,layers[3],out_channels=512,stride=1)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*4,num_classes)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.bn1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.maxpool(x)\n",
        "\n",
        "        x=self.layer1(x)\n",
        "        x=self.layer2(x)\n",
        "        x=self.layer3(x)\n",
        "        x=self.layer4(x)\n",
        "\n",
        "        x=self.avgpool(x)\n",
        "        x=x.reshape(x.shape[0],-1)\n",
        "        x=self.fc(x)\n",
        "\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def make_layer(self,block,num_residual_blocks, out_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride!=1 or self.in_channels != out_channels*4:\n",
        "            identity_downsample= nn.Sequential(nn.Conv2d(self.in_channels,out_channels*4,kernel_size=1,stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "        layers.append(block(self.in_channels,out_channels, identity_downsample,stride))\n",
        "        self.in_channels = out_channels*4\n",
        "\n",
        "        for i in range(num_residual_blocks -1):\n",
        "            layers.append(block(self.in_channels,out_channels))\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27MVZYGiIBiQ"
      },
      "outputs": [],
      "source": [
        "# Load the augmented data into a dataset\n",
        "data_transforms_res = transforms.Compose([\n",
        "    transforms.Resize(256), # Resize to a larger size to ensure all images are covered\n",
        "    transforms.CenterCrop(224), # Crop the center of the image to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "combined_data_dir = '/content/drive/MyDrive/MP_Dataset/autism/combined_dataset'\n",
        "combined_dataset = ImageFolder(combined_data_dir, transform=data_transforms_res)\n",
        "\n",
        "# Define the lengths of the training and validation sets\n",
        "train_size = len(combined_dataset)\n",
        "validation_size = int(train_size * 0.2) # 20% of the data for validation\n",
        "train_size = train_size - validation_size # Adjust the training size\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, validation_dataset = random_split(combined_dataset, [train_size, validation_size])\n",
        "\n",
        "# Create DataLoaders for the training and validation sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "# Update the dataset_sizes dictionary to include the validation set\n",
        "dataset_sizes = {\n",
        "    'train': train_size,\n",
        "    'validation': validation_size\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjDW_Q21lXji"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "model_save_path = '/content/drive/MyDrive/MP_Dataset/SpectrumSense/Model_checkpoints/ResNET50/Resnet_50_30epoch.pth'\n",
        "checkpoint_exists = os.path.isfile(model_save_path)\n",
        "\n",
        "# Initializing the model\n",
        "model = ResNet(block, [3, 4, 6, 3], image_channels=3, num_classes=len(combined_dataset.classes))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
        "\n",
        "# Load the checkpoint if it exists\n",
        "if checkpoint_exists:\n",
        "    checkpoint = torch.load(model_save_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # Move the model to the GPU\n",
        "    model = model.to(device)\n",
        "    # Move the optimizer's state dict to the GPU\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.to(device)\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    last_loss = checkpoint['loss']\n",
        "else:\n",
        "    # If the checkpoint does not exist, initialize the last epoch and loss\n",
        "    last_epoch = 0\n",
        "    last_loss = 0.0\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(last_epoch + 1, num_epochs + 1):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'validation']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Use the appropriate DataLoader based on the phase\n",
        "        if phase == 'train':\n",
        "            dataloader = train_dataloader\n",
        "        else:\n",
        "            dataloader = validation_dataloader\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    # Save the model state after each epoch\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': epoch_loss,\n",
        "        'accuracy': epoch_acc,\n",
        "    }, model_save_path)\n",
        "\n",
        "print('Training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azhx5AO3lZp-"
      },
      "outputs": [],
      "source": [
        "model_save_path = '/content/drive/MyDrive/MP_Dataset/SpectrumSense/Model_checkpoints/ResNET50/Resnet_50_30epoch.pth'\n",
        "\n",
        "# Path to the test image\n",
        "test_image_path = '/content/drive/MyDrive/MP_Dataset/autism/test/autistic/025.jpg'\n",
        "\n",
        "\n",
        "#ASK ME BEFORE RUNNING THIS CODE\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(256), # Resize to a larger size to ensure all images are covered\n",
        "    transforms.CenterCrop(224), # Crop the center of the image to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "model = ResNet(block,[3, 4, 6, 3], image_channels=3, num_classes=len(combined_dataset.classes))\n",
        "checkpoint = torch.load(model_save_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval() # Set the model to evaluation mode\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load and transform the test image\n",
        "image = Image.open(test_image_path)\n",
        "image = data_transforms_test(image).unsqueeze(0)\n",
        "\n",
        "image = image.to(device)\n",
        "\n",
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(image)\n",
        "    probabilities = F.softmax(outputs, dim=1)\n",
        "    _, preds = torch.max(probabilities, 1)\n",
        "\n",
        "class_names = ['Not Autistic', 'Autistic']\n",
        "\n",
        "# Predicted class name\n",
        "predicted_class = class_names[preds.item()]\n",
        "\n",
        "# Print the probabilities of confidence rate for each class\n",
        "print(f'Predicted class: {predicted_class}')\n",
        "print(f'Probabilities: {probabilities.tolist()}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}